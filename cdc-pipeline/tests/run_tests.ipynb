{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CDC Pipeline Unit Tests Runner\n",
        "\n",
        "This notebook executes unit tests for the CDC pipeline using **dbx_test** and **pytest**.\n",
        "\n",
        "## Features\n",
        "- **pytest fixtures**: Reusable test setup components\n",
        "- **pytest.mark.parametrize**: Data-driven testing with multiple parameter sets\n",
        "- **dbx_test integration**: Execute tests directly from Databricks notebooks\n",
        "\n",
        "## Test Coverage\n",
        "- `01-CDC-CDF-simple-pipeline.ipynb`: Deduplication, merge logic, CDF processing\n",
        "- `02-CDC-CDF-full-multi-tables.ipynb`: Multi-table processing, concurrent operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install dbx-test pytest pytest-html --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Restart Python to pick up new packages\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup Test Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pytest\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the notebook's directory path\n",
        "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
        "workspace_path = \"/Workspace\" + notebook_path.rsplit(\"/\", 1)[0]\n",
        "\n",
        "# Add tests directory to Python path\n",
        "if workspace_path not in sys.path:\n",
        "    sys.path.insert(0, workspace_path)\n",
        "\n",
        "print(f\"Test directory: {workspace_path}\")\n",
        "print(f\"Python path updated: {workspace_path in sys.path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define Test Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test configuration\n",
        "TEST_CONFIG = {\n",
        "    \"verbose\": True,\n",
        "    \"show_locals\": True,\n",
        "    \"capture\": \"no\",  # Show print statements during tests\n",
        "    \"markers\": None,  # Run all markers, or specify: \"not slow\"\n",
        "    \"test_files\": [\n",
        "        \"test_simple_pipeline.py\",\n",
        "        \"test_multi_tables.py\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Test Configuration:\")\n",
        "for key, value in TEST_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run All Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_pytest_tests(test_path: str, verbose: bool = True, \n",
        "                     show_locals: bool = True, markers: str = None) -> int:\n",
        "    \"\"\"\n",
        "    Execute pytest tests and return exit code.\n",
        "    \n",
        "    Args:\n",
        "        test_path: Path to test file or directory\n",
        "        verbose: Enable verbose output\n",
        "        show_locals: Show local variables in tracebacks\n",
        "        markers: Pytest marker expression to filter tests\n",
        "        \n",
        "    Returns:\n",
        "        pytest exit code (0 = success, non-zero = failure)\n",
        "    \"\"\"\n",
        "    args = [test_path]\n",
        "    \n",
        "    if verbose:\n",
        "        args.append(\"-v\")\n",
        "    \n",
        "    if show_locals:\n",
        "        args.append(\"--tb=short\")\n",
        "        args.append(\"--showlocals\")\n",
        "    \n",
        "    if markers:\n",
        "        args.extend([\"-m\", markers])\n",
        "    \n",
        "    # Add color output\n",
        "    args.append(\"--color=yes\")\n",
        "    \n",
        "    # Disable warnings for cleaner output\n",
        "    args.append(\"-W\")\n",
        "    args.append(\"ignore::DeprecationWarning\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: pytest {' '.join(args)}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    return pytest.main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all tests\n",
        "exit_code = run_pytest_tests(\n",
        "    test_path=workspace_path,\n",
        "    verbose=TEST_CONFIG[\"verbose\"],\n",
        "    show_locals=TEST_CONFIG[\"show_locals\"],\n",
        "    markers=TEST_CONFIG[\"markers\"]\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "if exit_code == 0:\n",
        "    print(\"✅ All tests PASSED!\")\n",
        "else:\n",
        "    print(f\"❌ Tests FAILED with exit code: {exit_code}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Specific Test Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run only Simple Pipeline tests\n",
        "print(\"Running Simple Pipeline Tests...\")\n",
        "simple_pipeline_result = run_pytest_tests(\n",
        "    test_path=f\"{workspace_path}/test_simple_pipeline.py\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run only Multi-Table tests\n",
        "print(\"Running Multi-Table Tests...\")\n",
        "multi_table_result = run_pytest_tests(\n",
        "    test_path=f\"{workspace_path}/test_multi_tables.py\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Specific Test Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run specific test class - Deduplication tests\n",
        "print(\"Running Deduplication Tests Only...\")\n",
        "dedup_result = run_pytest_tests(\n",
        "    test_path=f\"{workspace_path}/test_simple_pipeline.py::TestDeduplication\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run specific test class - Merge Logic tests\n",
        "print(\"Running Merge Logic Tests Only...\")\n",
        "merge_result = run_pytest_tests(\n",
        "    test_path=f\"{workspace_path}/test_simple_pipeline.py::TestMergeLogic\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Parameterized Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run a specific parameterized test\n",
        "print(\"Running Parameterized Deduplication Test...\")\n",
        "param_result = run_pytest_tests(\n",
        "    test_path=f\"{workspace_path}/test_simple_pipeline.py::TestDeduplication::test_deduplication_keeps_single_record\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Generate Test Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_report(test_path: str, report_path: str = \"/tmp/test_report.html\") -> int:\n",
        "    \"\"\"\n",
        "    Generate HTML test report using pytest-html.\n",
        "    \n",
        "    Args:\n",
        "        test_path: Path to test file or directory\n",
        "        report_path: Output path for HTML report\n",
        "        \n",
        "    Returns:\n",
        "        pytest exit code\n",
        "    \"\"\"\n",
        "    args = [\n",
        "        test_path,\n",
        "        \"-v\",\n",
        "        \"--tb=short\",\n",
        "        f\"--html={report_path}\",\n",
        "        \"--self-contained-html\",\n",
        "        \"-W\", \"ignore::DeprecationWarning\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"Generating test report at: {report_path}\")\n",
        "    exit_code = pytest.main(args)\n",
        "    \n",
        "    if exit_code == 0:\n",
        "        print(f\"\\n✅ Report generated successfully: {report_path}\")\n",
        "    \n",
        "    return exit_code\n",
        "\n",
        "# Generate report\n",
        "report_exit_code = generate_test_report(workspace_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Summary and Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display test statistics\n",
        "print(\"Test Modules and Classes:\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"test_simple_pipeline.py:\")\n",
        "print(\"  - TestDeduplication: Tests for CDC data deduplication\")\n",
        "print(\"  - TestMergeLogic: Tests for MERGE INTO operations\")\n",
        "print(\"  - TestCDFProcessing: Tests for Change Data Feed\")\n",
        "print(\"  - TestDataCleaning: Tests for data transformations\")\n",
        "print(\"  - TestEndToEndPipeline: Integration tests\")\n",
        "print(\"  - TestSchemaHandling: Schema validation tests\")\n",
        "print()\n",
        "print(\"test_multi_tables.py:\")\n",
        "print(\"  - TestMultiTableDeduplication: Multi-table dedup tests\")\n",
        "print(\"  - TestColumnMapping: Column mapping tests\")\n",
        "print(\"  - TestMultiTableMergeLogic: Multi-table merge tests\")\n",
        "print(\"  - TestSchemaValidation: Schema validation tests\")\n",
        "print(\"  - TestBatchProcessing: Batch processing tests\")\n",
        "print(\"  - TestConcurrentProcessing: Concurrency tests\")\n",
        "print(\"  - TestErrorHandling: Error handling tests\")\n",
        "print(\"  - TestDataIntegrity: Data integrity tests\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. dbx_test Integration for Remote Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dbx_test integration for running tests on Databricks clusters\n",
        "try:\n",
        "    from dbx_test import dbx_test\n",
        "    \n",
        "    # Example dbx_test configuration\n",
        "    DBX_TEST_CONFIG = {\n",
        "        \"cluster_id\": None,  # Set your cluster ID here\n",
        "        \"test_path\": workspace_path,\n",
        "        \"timeout\": 600,  # 10 minutes\n",
        "    }\n",
        "    \n",
        "    print(\"dbx_test is available for remote test execution.\")\n",
        "    print(\"To run tests remotely, configure DBX_TEST_CONFIG with your cluster_id.\")\n",
        "    print()\n",
        "    print(\"Example usage:\")\n",
        "    print('  !dbx_test run --cluster-id <your-cluster-id> --test-path tests/')\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"dbx_test not available. Install with: %pip install dbx-test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Custom Test Execution with Filters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_filtered_tests(test_path: str, keyword: str = None, \n",
        "                       exclude_keyword: str = None) -> int:\n",
        "    \"\"\"\n",
        "    Run tests with keyword filtering.\n",
        "    \n",
        "    Args:\n",
        "        test_path: Path to test directory\n",
        "        keyword: Only run tests matching this keyword (-k)\n",
        "        exclude_keyword: Exclude tests matching this keyword\n",
        "        \n",
        "    Returns:\n",
        "        pytest exit code\n",
        "    \"\"\"\n",
        "    args = [test_path, \"-v\", \"--tb=short\"]\n",
        "    \n",
        "    if keyword and exclude_keyword:\n",
        "        args.extend([\"-k\", f\"{keyword} and not {exclude_keyword}\"])\n",
        "    elif keyword:\n",
        "        args.extend([\"-k\", keyword])\n",
        "    elif exclude_keyword:\n",
        "        args.extend([\"-k\", f\"not {exclude_keyword}\"])\n",
        "    \n",
        "    return pytest.main(args)\n",
        "\n",
        "# Example: Run only tests with 'dedup' in the name\n",
        "# run_filtered_tests(workspace_path, keyword=\"dedup\")\n",
        "\n",
        "# Example: Run all tests except 'concurrent'\n",
        "# run_filtered_tests(workspace_path, exclude_keyword=\"concurrent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Quick Test Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick validation - run a subset of fast tests\n",
        "print(\"Quick Test Validation - Running fast tests only...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Run just the basic tests for quick validation\n",
        "quick_tests = [\n",
        "    \"TestDeduplication::test_deduplication_keeps_single_record\",\n",
        "    \"TestMergeLogic::test_insert_new_record\",\n",
        "    \"TestMultiTableDeduplication::test_deduplication_per_table\"\n",
        "]\n",
        "\n",
        "for test in quick_tests:\n",
        "    # Find the correct file for each test\n",
        "    if \"MultiTable\" in test:\n",
        "        test_file = \"test_multi_tables.py\"\n",
        "    else:\n",
        "        test_file = \"test_simple_pipeline.py\"\n",
        "    \n",
        "    result = pytest.main([f\"{workspace_path}/{test_file}::{test}\", \"-v\", \"--tb=line\"])\n",
        "    status = \"✅\" if result == 0 else \"❌\"\n",
        "    print(f\"{status} {test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Test Documentation\n",
        "\n",
        "### Fixtures Available (from conftest.py)\n",
        "\n",
        "| Fixture | Scope | Description |\n",
        "|---------|-------|-------------|\n",
        "| `spark` | session | SparkSession for testing |\n",
        "| `cdc_schema` | module | Schema for CDC input data |\n",
        "| `silver_schema` | module | Schema for Silver layer |\n",
        "| `gold_schema` | module | Schema for Gold layer |\n",
        "| `base_timestamp` | function | Base timestamp for test data |\n",
        "| `sample_cdc_data` | function | Sample CDC data |\n",
        "| `sample_cdc_with_updates` | function | CDC data with updates |\n",
        "| `sample_cdc_with_deletes` | function | CDC data with deletes |\n",
        "| `sample_cdc_with_duplicates` | function | CDC data for dedup testing |\n",
        "| `create_test_table` | function | Factory for creating test tables |\n",
        "\n",
        "### Parametrized Tests\n",
        "\n",
        "Many tests use `@pytest.mark.parametrize` for data-driven testing:\n",
        "\n",
        "```python\n",
        "@pytest.mark.parametrize(\"num_duplicates,expected_count\", [\n",
        "    (1, 1),   # Single record\n",
        "    (3, 1),   # Three duplicates\n",
        "    (5, 1),   # Five duplicates\n",
        "])\n",
        "def test_deduplication_keeps_single_record(...):\n",
        "    ...\n",
        "```\n",
        "\n",
        "### Running Specific Parameter Sets\n",
        "\n",
        "```python\n",
        "# Run specific parameter combination\n",
        "pytest tests/test_simple_pipeline.py::TestDeduplication::test_deduplication_keeps_single_record[3-1] -v\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
